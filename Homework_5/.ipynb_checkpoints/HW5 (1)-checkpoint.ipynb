{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XP3aHDHjglMZ"
   },
   "source": [
    "# Please read:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62Q3o6XUglMf"
   },
   "source": [
    "We have already defined the dataset below. \n",
    "And also have defined X_train and y_train. Please build a model and test it with X_test.\n",
    "\n",
    "\n",
    "You should build a neural network model in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcikv29cglMg"
   },
   "source": [
    "# Section A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1VQOW14glMg",
    "outputId": "a15f0d26-3532-482e-8cc4-cb0ba84cf214"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "B2S2aVQ2glMh",
    "outputId": "d97f2c3a-c48d-4781-848f-ca99433778f4",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.grid('off')\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.grid('off')\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.grid('off')\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "plt.grid('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g1eLiDpiglMi"
   },
   "outputs": [],
   "source": [
    "# In the preceding code, we are importing the relevant Keras files and are also importing the MNIST dataset \n",
    "#(which is provided as a built-in dataset in Keras). \n",
    "\n",
    "# The MNIST dataset contains images of digits where the images are of 28 x 28 in shape. \n",
    "# You can see in the plots what they will look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPKf_d2rglMj"
   },
   "source": [
    "# Section B - HW Neural Network starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "t1MCeiNvglMj"
   },
   "outputs": [],
   "source": [
    "# 1. Import the relevant packages and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IYNl70FgglMj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9Oxah-oJglMj"
   },
   "outputs": [],
   "source": [
    "#2. Preprocess the targets (convert them into one-hot encoded vectors) so that we can perform optimization on top of them:\n",
    "#We shall be minimizing categorical cross entropy loss\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "#- 2points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4g3z9B98glMk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train_reshaped = X_train.reshape(X_train.shape[0], 28*28)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], 28*28)\n",
    "\n",
    "print(X_train_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8g4jBJECglMk"
   },
   "outputs": [],
   "source": [
    "#3. Initialize a model - 1 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_JL06EmrglMk"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tFRFQXaglMk"
   },
   "source": [
    "# Define the model architecture:\n",
    "Specify the number of units in a hidden layer\n",
    "Specify the activation function that is to be performed in a hidden layer\n",
    "Specify the number of hidden layers\n",
    "Specify the loss function that we want to minimize\n",
    "Provide the optimizer that will minimize the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "sdLD4oUbglMl"
   },
   "outputs": [],
   "source": [
    "#5. Fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Vv6gkjOgglMl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                330       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 8,600\n",
      "Trainable params: 8,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(10, input_dim = 28*28, activation = 'relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 1.0386 - accuracy: 0.6625\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.9364 - accuracy: 0.7000\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.8506 - accuracy: 0.7337\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.7811 - accuracy: 0.7664\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.7461 - accuracy: 0.7765\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.7241 - accuracy: 0.7824\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.7153 - accuracy: 0.7841\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.7013 - accuracy: 0.7879\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6878 - accuracy: 0.7900\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6765 - accuracy: 0.7952\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6709 - accuracy: 0.7939\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6601 - accuracy: 0.7972\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6539 - accuracy: 0.8003\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6462 - accuracy: 0.8013\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6389 - accuracy: 0.8050\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6362 - accuracy: 0.8047\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6232 - accuracy: 0.8096\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.6004 - accuracy: 0.8200\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.8302\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5448 - accuracy: 0.8373\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5198 - accuracy: 0.8446\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4946 - accuracy: 0.8518\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4615 - accuracy: 0.8613\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4378 - accuracy: 0.8691\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4271 - accuracy: 0.8713\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4184 - accuracy: 0.8755\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4100 - accuracy: 0.8780\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3997 - accuracy: 0.8808\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3949 - accuracy: 0.8827\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3895 - accuracy: 0.8836\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3853 - accuracy: 0.8840\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3782 - accuracy: 0.8869\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3722 - accuracy: 0.8868\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3674 - accuracy: 0.8887\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8904\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3584 - accuracy: 0.8908\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3500 - accuracy: 0.8945\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3440 - accuracy: 0.8958\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3375 - accuracy: 0.8974\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8985\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.9005\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3290 - accuracy: 0.9018\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3213 - accuracy: 0.9034\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3221 - accuracy: 0.9022\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3184 - accuracy: 0.9026\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3172 - accuracy: 0.9046\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3108 - accuracy: 0.9062\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3075 - accuracy: 0.9074\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3059 - accuracy: 0.9088\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3051 - accuracy: 0.9084\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3023 - accuracy: 0.9085\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2999 - accuracy: 0.9099\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2985 - accuracy: 0.9101\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2992 - accuracy: 0.9094\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2953 - accuracy: 0.9105\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2931 - accuracy: 0.9113\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2914 - accuracy: 0.9114\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2915 - accuracy: 0.9123\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2902 - accuracy: 0.9128\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2910 - accuracy: 0.9123\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2891 - accuracy: 0.9131: 0s - loss: 0.2893 - accuracy\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2852 - accuracy: 0.9134\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2877 - accuracy: 0.9129\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2860 - accuracy: 0.9137\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2846 - accuracy: 0.9136\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2823 - accuracy: 0.9144\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2817 - accuracy: 0.9146\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2788 - accuracy: 0.9161\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2804 - accuracy: 0.9153\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2784 - accuracy: 0.9160\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2818 - accuracy: 0.9151\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.9166\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2759 - accuracy: 0.9179\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2776 - accuracy: 0.9162\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2768 - accuracy: 0.9169\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2747 - accuracy: 0.9186\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2710 - accuracy: 0.9177\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2719 - accuracy: 0.9178\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2730 - accuracy: 0.9180\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2718 - accuracy: 0.9181\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2706 - accuracy: 0.9190\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2707 - accuracy: 0.9187\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2690 - accuracy: 0.9185\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2674 - accuracy: 0.9198\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2678 - accuracy: 0.9202\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2688 - accuracy: 0.9196\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2630 - accuracy: 0.9218\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2693 - accuracy: 0.9193\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2646 - accuracy: 0.9202\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.9201\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2637 - accuracy: 0.9204\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2628 - accuracy: 0.9202\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2651 - accuracy: 0.9202\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2626 - accuracy: 0.9213: 0s - los\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2619 - accuracy: 0.9208\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2612 - accuracy: 0.9225\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2619 - accuracy: 0.9221\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2609 - accuracy: 0.9219\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2587 - accuracy: 0.9231\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2622 - accuracy: 0.9215\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2632 - accuracy: 0.9209\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2596 - accuracy: 0.9217\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2591 - accuracy: 0.9225\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2571 - accuracy: 0.9225\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2559 - accuracy: 0.9228\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2582 - accuracy: 0.9220\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2575 - accuracy: 0.9226\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2552 - accuracy: 0.9231\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2584 - accuracy: 0.9227\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.2574 - accuracy: 0.9221\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2554 - accuracy: 0.9226\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2549 - accuracy: 0.9234\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2561 - accuracy: 0.9225\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2560 - accuracy: 0.9228\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2539 - accuracy: 0.9237\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2534 - accuracy: 0.9238\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2547 - accuracy: 0.9235\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2546 - accuracy: 0.9235\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2535 - accuracy: 0.9235\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2544 - accuracy: 0.9237\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.9241\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2528 - accuracy: 0.9242\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.9237\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2509 - accuracy: 0.9245\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2514 - accuracy: 0.9242\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2510 - accuracy: 0.9239\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2526 - accuracy: 0.9234\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2489 - accuracy: 0.9258\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2501 - accuracy: 0.9248\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2520 - accuracy: 0.9239\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2497 - accuracy: 0.9241\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2499 - accuracy: 0.9241\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2509 - accuracy: 0.9251\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2504 - accuracy: 0.9251\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2497 - accuracy: 0.9245\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2474 - accuracy: 0.9261\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2484 - accuracy: 0.9249\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.9248\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2483 - accuracy: 0.9250\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2485 - accuracy: 0.9245\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2472 - accuracy: 0.9259\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2481 - accuracy: 0.9250\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2475 - accuracy: 0.9249\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2468 - accuracy: 0.9255\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2469 - accuracy: 0.9255: 0s - loss: 0.2409 \n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2469 - accuracy: 0.9254\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2473 - accuracy: 0.9261\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2475 - accuracy: 0.9257\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2459 - accuracy: 0.9256\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2469 - accuracy: 0.9255\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2464 - accuracy: 0.9262\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.9243\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.9255\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.9253\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.9265\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2439 - accuracy: 0.9255\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.9259\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.9260\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.9261\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2449 - accuracy: 0.9262\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2434 - accuracy: 0.9264\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2449 - accuracy: 0.9267\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2449 - accuracy: 0.9255\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2434 - accuracy: 0.9266\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2462 - accuracy: 0.9255\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2443 - accuracy: 0.9268\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2428 - accuracy: 0.9270\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2419 - accuracy: 0.9266\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2437 - accuracy: 0.9267\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.9257\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2411 - accuracy: 0.9271\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2411 - accuracy: 0.9265\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2430 - accuracy: 0.9264\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2397 - accuracy: 0.9276\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2420 - accuracy: 0.9270\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2401 - accuracy: 0.9276\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2413 - accuracy: 0.9275\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2429 - accuracy: 0.9266\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2428 - accuracy: 0.9269\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2405 - accuracy: 0.9268\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2417 - accuracy: 0.9269\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2401 - accuracy: 0.9275\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2388 - accuracy: 0.9280\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2396 - accuracy: 0.9286\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2414 - accuracy: 0.9268\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2408 - accuracy: 0.9262\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2406 - accuracy: 0.9281\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2417 - accuracy: 0.9265\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2414 - accuracy: 0.9262\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2384 - accuracy: 0.9280\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2410 - accuracy: 0.9278\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2387 - accuracy: 0.9278\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2398 - accuracy: 0.9274\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2389 - accuracy: 0.9281\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2370 - accuracy: 0.9278\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2387 - accuracy: 0.9277\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2393 - accuracy: 0.9275\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2403 - accuracy: 0.9271\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2383 - accuracy: 0.9284\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2393 - accuracy: 0.9282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fddc7fc8cd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_reshaped, y_train_encoded,epochs=200, batch_size=200, verbose=1, shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "y7Z2yb6VglMl"
   },
   "outputs": [],
   "source": [
    "#6. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sDr_XdNWglMl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:93.09%\n",
      "\n",
      "Testing Accuracy:90.62%\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                330       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 8,600\n",
      "Trainable params: 8,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(X_train_reshaped, y_train_encoded, verbose=False)\n",
    "print(\"Training Accuracy:%.2f%%\\n\"%(scores[1]*100))\n",
    "scores=model.evaluate(X_test_reshaped, y_test_encoded, verbose=False)\n",
    "print(\"Testing Accuracy:%.2f%%\\n\"%(scores[1]*100))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80paH829glMl"
   },
   "outputs": [],
   "source": [
    "#7. Calculate the accuracy and loss values on top of the test dataset - 2 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "eRbowNQnglMm"
   },
   "outputs": [],
   "source": [
    "loss_train, accuracy_train = model.evaluate(X_train_reshaped, y_train_encoded, verbose=False)\n",
    "loss_test, accuracy_test = model.evaluate(X_test_reshaped, y_test_encoded, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "54iKmybjglMm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Train: 0.2279907912015915\n",
      "Accuracy Train: 0.930899977684021 \n",
      "\n",
      "Loss Test: 0.3505338430404663\n",
      "Accuracy Test: 0.9061999917030334\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss Train:\", loss_train)\n",
    "print(\"Accuracy Train:\", accuracy_train, \"\\n\")\n",
    "\n",
    "print(\"Loss Test:\", loss_test)\n",
    "print(\"Accuracy Test:\", accuracy_test)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
